---
title: "Homework 6"
author: "Hongji Jiang"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(purrr)
library(modelr)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```
### Problem 1

To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r weather_df, cache = TRUE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 

The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 

# Problem 2

## Import and tidy up the dataset
```{r}
homicide_data = read_csv("./data/homicide-data.csv")
```
This dataset has `r nrow(homicide_data)` rows and `r ncol(homicide_data)` columns. The columns(variables) are `r names(homicide_data)` and each row is a homicide incident.
```{r}
homicide_data=
  homicide_data %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    solved = ifelse(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)
    ) %>%
    filter(city_state != "Dallas, Tx", city_state != "Phoenix, AZ", city_state != "Kansas City, MO", city_state != "Tulsa, AL") %>% 
  filter(victim_race %in% c("Black", "White")) %>% 
  drop_na(victim_age)
```
Created a new variable `city_state` by concatenating city and state, seperateing with ','.
Omitted cities Dallas, TX; Phoenix, AZ; and Kansas City, MO– these don’t report victim race. 
Also omitted Tulsa, AL – this is a data entry mistake.

```{r}
logistic_Baltimore = 
  homicide_data %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) 
```
Use glm on the to fit a lofisitc regression model with resolved vs unresolved as the outcome and victim age, sex and race as predictors. Save the output of glm as an R object;

```{r}
logistic_Baltimore %>% 
  broom::glance()
```
Take a glance at the saved result.

```{r}
logistic_Baltimore %>% 
  broom::tidy() %>%
  mutate(OR = exp(estimate)) %>%
  mutate(
    lower_ci = exp(estimate-1.96*std.error),
    upper_ci = exp(estimate+1.96*std.error)
  ) %>% 
  filter(term == "victim_sexMale") %>%
  select(term, estimate, OR, lower_ci, upper_ci) %>% 
  knitr::kable(digits = 3)
```
Use broom tidy to tidy up the result. Get the odds ratio of case being solved comparing those with sex as male to those with sex as female and the 95% CI for it.

```{r}
logistic_all_cities = function(dataset) {
    dataset %>%
    glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) %>% 
    broom::tidy() %>% 
    mutate(
      OR = exp(estimate),
      lower_ci = exp(estimate - 1.96 * std.error),
      upper_ci = exp(estimate + 1.96 * std.error)) %>%
  filter(term == "victim_sexMale") %>%
  select(term, estimate, OR, lower_ci, upper_ci)
}
```
Create a function to fit the regression model and get the odds ratio and CI similar to the process we have done to Baltimore.
It is going to be applied to the data set in the next steps for each of the cities.

```{r}
logit_result_cities = 
  homicide_data %>% 
  nest(df = -city_state) %>% 
  mutate(
    result = map(df, logistic_all_cities)
  ) %>% 
  unnest(result) %>% 
  select(-df) 
```


```{r}

logit_result_cities %>% 
  knitr::kable(digits = 3)
```

```{r}
logit_result_cities %>% 
  mutate(
    city_state = fct_reorder(city_state, OR)
  ) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci)) +
  theme(axis.text.x = element_text(
      angle = 90)) 
```
Run glm on each city_state and get the Odds Ratio of case being solved comparing those with sex as male to those with sex as female, and also get the CI of that OR. Using geom_error bar to show the OR and the CI together in one plot. 
We can see that New York, NY has the smallest odds ratio of solving homicides comparing those identified as male to those identified as female. And Albuquerque, NM has the highest odds ratio of solving homicides comparing those identidied as male to those identified as female.

# Question 3 
```{r}
birthweight_data = 
  read_csv("./data/birthweight.csv") %>% 
    mutate(
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace),
    babysex = as.factor(babysex)
    ) %>%
  drop_na()
```
Import the data and drop na values.

```{r}
proposed_model = lm(bwt ~ fincome+blength+gaweeks, data = birthweight_data)
```
The proposed model I have is using using family monthly income (in hundreds, rounded), length at birth and gestational age as predictors. I hypothesize that income may be an important factor that is related to the birthweight since it is an indicator of social status.
```{r}
proposed_model %>%
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

```{r}
proposed_plot =
  birthweight_data %>% 
  modelr::add_residuals(proposed_model) %>%
  modelr::add_predictions(proposed_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.5, cex=0.3) +
  labs(
    title = "Residuals vs. Fitted values",
    x = "predicted values",
    y = "residuals")
proposed_plot
```
Show a plot of model residuals against fitted values.

```{r}
cv_df = crossv_mc(birthweight_data, 100)
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
cv_df = 
  cv_df %>% 
  mutate(proposed = map(train, ~lm(bwt ~ fincome+blength+gaweeks, data = birthweight_data)),
         compare_1 = map(train, ~lm(bwt ~ blength+gaweeks, data = birthweight_data)),
         compare_2  = map(train, ~lm(bwt ~ bhead + blength + babysex+ bhead*babysex + blength*babysex + bhead*blength + bhead*blength*babysex, data = birthweight_data))) %>%
  mutate(rmse_proposed = map2_dbl(proposed, test, ~rmse(model = .x, data = .y)),
         rmse_compare_1 = map2_dbl(compare_1, test, ~rmse(model = .x, data = .y)),
         rmse_compare_2 = map2_dbl(compare_2, test, ~rmse(model = .x, data = .y)))
cv_df
```

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "RMSEs of The 3 Models",
    x = "Models",
    y = "RMSEs"
  )
```
We can see the model compare_1 that using length at birth and gestational age as predictors (main effects only) has the largest RMSEs. And the model compare_2 that using head circumference, length, sex, and all interactions (including the three-way interaction) between these has the smallest RMSE of the three models.