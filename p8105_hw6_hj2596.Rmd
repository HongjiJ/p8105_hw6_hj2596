---
title: "Homework 6"
author: "Hongji Jiang"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(purrr)
library(modelr)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Problem 2

## Import and tidy up the dataset
```{r}
homicide_data = read_csv("./data/homicide-data.csv")
```
This dataset has `r nrow(homicide_data)` rows and `r ncol(homicide_data)` columns. The columns(variables) are `r names(homicide_data)` and each row is a homicide incident.
```{r}
homicide_data=
  homicide_data %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    solved = ifelse(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)
    ) %>%
    filter(city_state != "Dallas, Tx", city_state != "Phoenix, AZ", city_state != "Kansas City, MO", city_state != "Tulsa, AL") %>% 
  filter(victim_race %in% c("Black", "White")) %>% 
  drop_na(victim_age)
```
Created a new variable `city_state` by concatenating city and state, seperateing with ','.
Omitted cities Dallas, TX; Phoenix, AZ; and Kansas City, MO– these don’t report victim race. 
Also omitted Tulsa, AL – this is a data entry mistake.

```{r}
logistic_Baltimore = 
  homicide_data %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) 
```
Use glm on the to fit a lofisitc regression model with resolved vs unresolved as the outcome and victim age, sex and race as predictors. Save the output of glm as an R object;

```{r}
logistic_Baltimore %>% 
  broom::glance()
```
Take a glance at the saved result.

```{r}
logistic_Baltimore %>% 
  broom::tidy() %>%
  mutate(OR = exp(estimate)) %>%
  mutate(
    lower_ci = exp(estimate-1.96*std.error),
    upper_ci = exp(estimate+1.96*std.error)
  ) %>% 
  filter(term == "victim_sexMale") %>%
  select(term, estimate, OR, lower_ci, upper_ci) %>% 
  knitr::kable(digits = 3)
```
Use broom tidy to tidy up the result. Get the odds ratio of case being solved comparing those with sex as male to those with sex as female and the 95% CI for it.

```{r}
logistic_all_cities = function(dataset) {
    dataset %>%
    glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) %>% 
    broom::tidy() %>% 
    mutate(
      OR = exp(estimate),
      lower_ci = exp(estimate - 1.96 * std.error),
      upper_ci = exp(estimate + 1.96 * std.error)) %>%
  filter(term == "victim_sexMale") %>%
  select(term, estimate, OR, lower_ci, upper_ci)
}
```
Create a function to fit the regression model and get the odds ratio and CI similar to the process we have done to Baltimore.
It is going to be applied to the data set in the next steps for each of the cities.

```{r}
logit_result_cities = 
  homicide_data %>% 
  nest(df = -city_state) %>% 
  mutate(
    result = map(df, logistic_all_cities)
  ) %>% 
  unnest(result) %>% 
  select(-df) 
```


```{r}

logit_result_cities %>% 
  knitr::kable(digits = 3)
```

```{r}
logit_result_cities %>% 
  mutate(
    city_state = fct_reorder(city_state, OR)
  ) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci)) +
  theme(axis.text.x = element_text(
      angle = 90)) 
```
Run glm on each city_state and get the Odds Ratio of case being solved comparing those with sex as male to those with sex as female, and also get the CI of that OR. Using geom_error bar to show the OR and the CI together in one plot. 
We can see that New York, NY has the smallest odds ratio of solving homicides comparing those identified as male to those identified as female. And Albuquerque, NM has the highest odds ratio of solving homicides comparing those identidied as male to those identified as female.

# Question 3 
```{r}
birthweight_data = 
  read_csv("./data/birthweight.csv") %>% 
    mutate(
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace),
    babysex = as.factor(babysex)
    ) %>%
  drop_na()
```

```{r}
proposed_model = lm(bwt ~ fincome+blength+gaweeks, data = birthweight_data)
```
The proposed model I have is using using family monthly income (in hundreds, rounded), length at birth and gestational age as predictors.
```{r}
proposed_model %>%
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

```{r}
proposed_plot =
  birthweight_data %>% 
  modelr::add_residuals(proposed_model) %>%
  modelr::add_predictions(proposed_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.5, cex=0.3) +
  labs(
    title = "Residuals vs. Fitted values",
    x = "predicted values",
    y = "residuals")
proposed_plot
```

```{r}
cv_df = crossv_mc(birthweight_data, 100)
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
cv_df = 
  cv_df %>% 
  mutate(proposed = map(train, ~lm(bwt ~ fincome+blength+gaweeks, data = birthweight_data)),
         compare_1 = map(train, ~lm(bwt ~ blength+gaweeks, data = birthweight_data)),
         compare_2  = map(train, ~lm(bwt ~ bhead + blength + babysex+ bhead*babysex + blength*babysex + bhead*blength + bhead*blength*babysex, data = birthweight_data))) %>%
  mutate(rmse_proposed = map2_dbl(proposed, test, ~rmse(model = .x, data = .y)),
         rmse_compare_1 = map2_dbl(compare_1, test, ~rmse(model = .x, data = .y)),
         rmse_compare_2 = map2_dbl(compare_2, test, ~rmse(model = .x, data = .y)))
cv_df
```

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "RMSEs of The 3 Models",
    x = "Models",
    y = "RMSEs"
  )
```
We can see the model compare_1 that using length at birth and gestational age as predictors (main effects only) has the largest RMSEs. And the model compare_2 that using head circumference, length, sex, and all interactions (including the three-way interaction) between these has the smallest RMSE of the three models.